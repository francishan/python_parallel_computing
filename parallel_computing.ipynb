{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parallel Programming\n",
    "\n",
    "Once all the options in “serial (or sequential) processing” paradigm have been exhausted, and if we\n",
    "still need further speed-up, “parallel processing” is the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared memory - multiprocessing\n",
    "\n",
    "Processors share the access to the same memory. OpenMP is a typical example. OpenMP enables\n",
    "concurrently running multiple threads, with the runtime environment allocating threads to different\n",
    "processors. \n",
    "\n",
    "Python has Global Interpreter Lock (GIL), which prevents multiple native threads from\n",
    "executing Python bytecodes at once, and as a result, there is no OpenMP package for Python.\n",
    "\n",
    "Python's standard \"multiprocessing\" module implements the shared memory programing paradigm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to spawn a process\n",
    "\n",
    "The term \"spawn\" means the creation of a process by a parent process. The parent process can continue its execution asynchronously or wait until the child process ends its execution. \n",
    "\n",
    "The `multiprocessing` library allows the spawning of a process through the following steps:\n",
    "\n",
    "1. Build the object process\n",
    "2. Call its `start()` method. This method starts the process's activity\n",
    "3. Call its `join()` method. It waits until the process has completed its works and exited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called function in process: 0\n",
      "called function in process: 1\n",
      "called function in process: 2\n",
      "called function in process: 3\n",
      "called function in process: 4\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def call(i):\n",
    "    print('called function in process: %s' %i)\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Process_jobs = []\n",
    "    for i in range(5):\n",
    "        p = Process(target=call, args=(i,))\n",
    "        Process_jobs.append(p)\n",
    "        p.start()\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "Process::  Process1\n",
      "Was assigned PID::  21892\n",
      "Process::  Process2\n",
      "Was assigned PID::  21893\n",
      "Process::  Process3\n",
      "Was assigned PID::  21894\n",
      "Process::  Process4\n",
      "Was assigned PID::  21895\n",
      "Process::  Process5\n",
      "Was assigned PID::  21896\n",
      "Process::  Process6\n",
      "Was assigned PID::  21897\n",
      "Process::  Process7\n",
      "Was assigned PID::  21898\n",
      "Process::  Process8\n",
      "Was assigned PID::  21899\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process\n",
    "\n",
    "# dummy function\n",
    "def f(id):\n",
    "    #This is a dummy function taking a parameter\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # get the number of CPUs\n",
    "    np = mp.cpu_count()\n",
    "    print('You have %d CPUs' %(np))\n",
    "\n",
    "    # Create the processes\n",
    "    p_list=[]\n",
    "    for i in range(1,np+1):\n",
    "        p = Process(target=f, name='Process'+str(i), args=(i,))\n",
    "        p_list.append(p)\n",
    "        print('Process:: ', p.name)\n",
    "        p.start()\n",
    "        print('Was assigned PID:: ', p.pid)\n",
    "\n",
    "    # Wait for all the processes to finish\n",
    "    for p in p_list:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the `Process` object within the main section `if __name__ == '__main__'` is important, because the child process created imports the script file where the target function is contained. Then, by instantiating the process object within this block, we prevent an infinite recursive call of such instantiations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to name a process\n",
    "\n",
    "It is very useful to associate a name to the processes as debugging an anpplication requires the processes to be well marked and identifiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting call_process \n",
      "\n",
      "Starting Process-28 \n",
      "\n",
      "Exiting call_process \n",
      "\n",
      "Exiting Process-28 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def call():\n",
    "    name = mp.current_process().name\n",
    "    print(\"Starting %s \\n\" %name)\n",
    "    time.sleep(3)\n",
    "    print(\"Exiting %s \\n\" %name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_with_name = mp.Process(name='call_process', target=call)\n",
    "    process_with_name.daemon = True\n",
    "    process_with_default_name = mp.Process(target=call)\n",
    "    process_with_name.start()\n",
    "    process_with_default_name.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use a process in a subclass\n",
    "\n",
    "* Define a new subclass of the `Process` class\n",
    "* Override the `_init__(self[, args])` method to add additional arguments\n",
    "* Override the `run(self[, args])` method to implement what Process should when it is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called run method in process: MyProcess-29\n",
      "called run method in process: MyProcess-30\n",
      "called run method in process: MyProcess-31\n",
      "called run method in process: MyProcess-32\n",
      "called run method in process: MyProcess-33\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "class MyProcess(mp.Process):\n",
    "    def run(self):\n",
    "        print('called run method in process: %s' %self.name)\n",
    "        return\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = MyProcess()\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to exchange objects between processes\n",
    "\n",
    "The `multiprocessing` library has two communication channels with which it manages the exchange of objects: queues and pipes.\n",
    "\n",
    "#### Using queue to exchange objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Producer : item 138 appended to queue producer-44\n",
      "Process Producer : item 88 appended to queue producer-44\n",
      "Processor Consumer: item 138 popped from by consumer-45 \n",
      "Process Producer : item 56 appended to queue producer-44\n",
      "\n",
      "Process Producer : item 159 appended to queue producer-44\n",
      "Process Producer : item 130 appended to queue producer-44\n",
      "Processor Consumer: item 88 popped from by consumer-45 \n",
      "\n",
      "Process Producer : item 156 appended to queue producer-44\n",
      "Process Producer : item 195 appended to queue producer-44\n",
      "Process Producer : item 56 appended to queue producer-44\n",
      "Processor Consumer: item 56 popped from by consumer-45 \n",
      "\n",
      "Process Producer : item 205 appended to queue producer-44\n",
      "Process Producer : item 242 appended to queue producer-44\n",
      "Processor Consumer: item 159 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 130 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 156 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 195 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 56 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 205 popped from by consumer-45 \n",
      "\n",
      "Processor Consumer: item 242 popped from by consumer-45 \n",
      "\n",
      "the queue is empty\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import time\n",
    "\n",
    "class producer(mp.Process):\n",
    "    def __init__(self, queue):\n",
    "        mp.Process.__init__(self)\n",
    "        self.queue = queue\n",
    "        \n",
    "    def run(self):\n",
    "        for i in range(10):\n",
    "            item = random.randint(0, 256)\n",
    "            self.queue.put(item)\n",
    "            print(\"Process Producer : item %d appended to queue %s\"\\\n",
    "                  % (item, self.name))\n",
    "            time.sleep(1)\n",
    "            #print(\"The size of queue is %s\" % self.queue.qsize()) # Unix system throws error\n",
    "            \n",
    "class consumer(mp.Process):\n",
    "    def __init__(self, queue):\n",
    "        mp.Process.__init__(self)\n",
    "        self.queue = queue\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if(self.queue.empty()):\n",
    "                print(\"the queue is empty\")\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "                item = self.queue.get()\n",
    "                print('Processor Consumer: item %d popped from by %s \\n'\\\n",
    "                     % (item, self.name))\n",
    "                time.sleep(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queue = mp.Queue()\n",
    "    process_producer = producer(queue)\n",
    "    process_consumer = consumer(queue)\n",
    "    process_producer.start()\n",
    "    process_consumer.start()\n",
    "    process_producer.join()\n",
    "    process_consumer.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pipes to exchange objects\n",
    "\n",
    "A pipe does the following:\n",
    "* Returns a pair of connection objects connected by a pipe\n",
    "* Every object has send/receive methods to communicate between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def create_items(pipe):\n",
    "    output_pipe, _ = pipe\n",
    "    for item in range(10):\n",
    "        output_pipe.send(item)\n",
    "    output_pipe.close()\n",
    "    \n",
    "def multiply_items(pipe_1, pipe_2):\n",
    "    close, input_pipe = pipe_1\n",
    "    close.close()\n",
    "    output_pipe, _ = pipe_2\n",
    "    try:\n",
    "        while True:\n",
    "            item = input_pipe.recv()\n",
    "            output_pipe.send(item * item)\n",
    "    except EOFError:\n",
    "        output_pipe.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # First process pipe with numbers from 0 to 9\n",
    "    pipe_1 = mp.Pipe(True)\n",
    "    process_pipe_1 = mp.Process(target=create_items, args=(pipe_1,))\n",
    "    process_pipe_1.start()\n",
    "    \n",
    "    # Second pipe\n",
    "    pipe_2 = mp.Pipe(True)\n",
    "    process_pipe_2 = mp.Process(target=multiply_items, args=(pipe_1, pipe_2,))\n",
    "    process_pipe_2.start()\n",
    "    \n",
    "    pipe_1[0].close()\n",
    "    pipe_2[0].close()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            print(pipe_2[1].recv())\n",
    "            \n",
    "    except EOFError:\n",
    "        print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to synchronize processes\n",
    "\n",
    "Multiple processes can work together to perform a given task. Usually, they share data. It is important that the access to shared data by various processes does not produce inconsistent data. \n",
    "\n",
    "Processes that coorperate by sharing data must therefore act in an orderly manner in order to access that data. \n",
    "\n",
    "* Lock: This object can be in one of the states: locked and unlocked. A lock object has two methods, `acquire()` and `release()`, to manage the access to a shared resource.\n",
    "* Event: This realizes simple communication between processes, one process signals an event and the other processes wait for it. An `Event` object has two methods, `set()` and `clear()`, to manage its own internal flag.\n",
    "* Condition: This object is used to synchronize parts of a workflow, in sequential or parallel processes. It has two basic methods, `wait()` is used to wait for a condition and `notify_all()` is used to communicate the condition that was applied.\n",
    "* Semaphore: This is used to share a common resource, for example, to support a fixed number of simultaneous connections\n",
    "* RLock: This defines the recursive `lock` object. The methods and functionality for `RLock` are the same as the `Threading` module\n",
    "* Barrier: This divides a program into phases as it requires all of the processes to reach it before any of them proceeds. Code that is executed after a barrier cannot be concurrent with the code executed before the barrier\n",
    "\n",
    "Here we show the use of `barrier()` to synchronize two processes. Say four processes, where process1 and process2 are managed by a barrier statement, while process3 and process4 have no synchronizations directives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process p2 - test_with_barrier ----> 2018-01-19 13:07:40.408318\n",
      "process p1 - test_with_barrier ----> 2018-01-19 13:07:40.408509\n",
      "process p4 - test_without_barrier ----> 2018-01-19 13:07:40.421257\n",
      "process p3 - test_without_barrier ----> 2018-01-19 13:07:40.421350\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Barrier, Lock, Process\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "def test_with_barrier(synchronizer, serializer):\n",
    "    name = mp.current_process().name\n",
    "    synchronizer.wait()\n",
    "    now = time()\n",
    "    with serializer:\n",
    "        print(\"process %s ----> %s\" % (name, datetime.fromtimestamp(now)))\n",
    "        \n",
    "def test_without_barrier():\n",
    "    name = mp.current_process().name\n",
    "    now = time()\n",
    "    print(\"process %s ----> %s\" % (name, datatime.fromtimestamp(now)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    synchronizer = Barrier(2) #2 stands for the total number of process\n",
    "    serializer = Lock()\n",
    "    Process(name='p1 - test_with_barrier', target=test_with_barrier, \\\n",
    "           args=(synchronizer, serializer)).start()\n",
    "    Process(name='p2 - test_with_barrier', target=test_with_barrier, \\\n",
    "           args=(synchronizer, serializer)).start()\n",
    "    Process(name='p3 - test_without_barrier', target=test_with_barrier, \\\n",
    "           args=(synchronizer, serializer)).start()\n",
    "    Process(name='p4 - test_without_barrier', target=test_with_barrier, \\\n",
    "           args=(synchronizer, serializer)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that process1 and process2 print out the same timestamps.\n",
    "\n",
    "### How to manage a state between processes\n",
    "Python multiprocessing provides a manager to coordinate shared information between all its users. A maanger object controls a server process that holds Python objects and llows other processes to manipulate them. \n",
    "\n",
    "A manager has the following properties:\n",
    "* It controls the server process that manages a shared object\n",
    "* It makes sure the shared object gets updated in all processes when anyone modifies it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 0, value = 0\n",
      "key = 1, value = 1\n",
      "key = 2, value = 4\n",
      "key = 3, value = 9\n",
      "key = 4, value = 16\n",
      "key = 5, value = 25\n",
      "key = 6, value = 36\n",
      "key = 7, value = 49\n",
      "key = 8, value = 64\n",
      "key = 9, value = 81\n",
      "Results: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def worker(dictionary, key, item):\n",
    "    dictionary[key] = item\n",
    "    print(\"key = %d, value = %d\" % (key, item))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mgr = mp.Manager()\n",
    "    dictionary = mgr.dict()\n",
    "    jobs = [mp.Process(target=worker, args=(dictionary, i, i**2)) for i in range(10)]\n",
    "    \n",
    "    for j in jobs:\n",
    "        j.start()\n",
    "    for j in jobs:\n",
    "        j.join()\n",
    "    \n",
    "    print('Results:', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use a process pool\n",
    "The multiprocessing library provides the `Pool` class for simple parallel processing tasks. The `Pool` class has the following methods:\n",
    "`apply()`: It blocks until the result is ready\n",
    "`apply_async()`: This is a variant of the `apply()` method, which returns a result object. It is an asynchronous operation that will not lock the main thread until all the child classes are executed\n",
    "`map()`: It blocks until the result is ready, this method chops the iterable data in a number of chunks that submits to the process pool as separate tasks. \n",
    "`map_async()`: If a callback is specified, then it should be callable, which accepts a single argument. When the result becomes ready, a callback is applied to it (unless the call failed). A callback should be completed immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def square(data):\n",
    "    result = data*data\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = list(range(100))\n",
    "    pool = mp.Pool(processes=4)\n",
    "    pool_outputs = pool.map(square, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Pool:', pool_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square(data):\n",
    "    result = data*data\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = list(range(100))\n",
    "    with Pool(4) as p:\n",
    "        print('Pool:', p.map(square, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial vs. parallel programming\n",
    "\n",
    "Let's revisit the case of computing Pi using numerical integration. Now we want to calculate the Pi for multiple times with different number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415927369231227, 3.14159267442312, 3.141592662849059, 3.141592658798146, 3.1415926569231227, 3.1415926559046072, 3.1415926552904714, 3.1415926548918773]\n",
      "Time taken 0.00751805305480957 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(1000, 9000, 1000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415927369231227, 3.14159267442312, 3.141592662849059, 3.141592658798146, 3.1415926569231227, 3.1415926559046072, 3.1415926552904714, 3.1415926548918773]\n",
      "Time taken 0.17608308792114258 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000, 9000, 1000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel model actually takes much longer time!! How could this happen?\n",
    "\n",
    "Let's assume we want more CPU intensive task, by increasing the number of steps by three order of maginitude when estimating Pi value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 6.243754863739014 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(1000000, 9000000, 1000000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 1.9258959293365479 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000000, 9000000, 1000000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the paralle model performs faster. It is because tasks are performed by multiple cores.\n",
    "\n",
    "What if we keep increasing the computation intesntity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415926535904264, 3.141592653590478, 3.141592653589358]\n",
      "Time taken 107.65656399726868 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(100000000, 900000000, 100000000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 2.1180169582366943 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000000, 9000000, 1000000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the benchmark to understand how multi-core parallel computing can be beneificial to computing intensive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = [10 ** n for n in range(0,5)]\n",
    "\n",
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    start = time.time()\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    end = time.time()\n",
    "        \n",
    "    return (num_steps, pi, end-start)\n",
    "\n",
    "def serial():\n",
    "    return [Pi(num_steps) for num_steps in width]\n",
    "\n",
    "def multiprocess(processes):\n",
    "    pool = mp.Pool(processes=processes)\n",
    "    results = [pool.map(Pi, width)]\n",
    "    #results = [p.get() for p in results]\n",
    "    #results.sort() # to sort the results by input window width\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-756f59b0d202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7a245fc08aee>\u001b[0m in \u001b[0;36mmultiprocess\u001b[0;34m(processes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#results = [p.get() for p in results]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "multiprocess(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-52-7a245fc08aee>\", line 7, in Pi\n    start = time.time()\nNameError: name 'time' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a3ef17b1fb8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7a245fc08aee>\u001b[0m in \u001b[0;36mmultiprocess\u001b[0;34m(processes)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m#results = [p.get() for p in results]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#results.sort() # to sort the results by input window width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "multiprocess(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1c191444a03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mserial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-7a245fc08aee>\u001b[0m in \u001b[0;36mserial\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-7a245fc08aee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-7a245fc08aee>\u001b[0m in \u001b[0;36mPi\u001b[0;34m(num_steps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "serial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-143-8cf4733f9953>\", line 9, in monte_carlo_pi_part\n    for i in range(n):\nTypeError: 'float' object cannot be interpreted as an integer\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-8cf4733f9953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# parallel map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonte_carlo_pi_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Esitmated value of Pi:: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ],
     "output_type": "error"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-342:\n",
      "Process ForkPoolWorker-346:\n",
      "Process ForkPoolWorker-340:\n",
      "Process ForkPoolWorker-341:\n",
      "Process ForkPoolWorker-344:\n",
      "Process ForkPoolWorker-345:\n",
      "Process ForkPoolWorker-347:\n",
      "Process ForkPoolWorker-343:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#caculate the number of points in the unit circle\n",
    "#out of n points\n",
    "def monte_carlo_pi_part(n):    \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        \n",
    "        # if it is within the unit circle\n",
    "        if x*x + y*y <= 1:\n",
    "            count=count+1\n",
    "    return count\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "\n",
    "    # Nummber of points to use for the Pi estimation\n",
    "    n = 10000000\n",
    "    \n",
    "    # iterable with a list of points to generate in each worker\n",
    "    # each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "    part_count=[n/np for i in range(np)]\n",
    "\n",
    "    pool = Pool(processes=np)   \n",
    "\n",
    "    # parallel map\n",
    "    count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "    print(\"Esitmated value of Pi:: \", sum(count)/(n*1.0)*4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use the multiprocessing to calculate the sum of prime numbers less than n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37550402023, 142913828922, 312471072265]\n",
      "Time taken = 23.71322\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def sum_prime(num):\n",
    "    \n",
    "    sum_of_primes = 0\n",
    "\n",
    "    ix = 2\n",
    "\n",
    "    while ix <= num:\n",
    "        if is_prime(ix):\n",
    "            sum_of_primes += ix\n",
    "        ix += 1\n",
    "\n",
    "    return sum_of_primes\n",
    "\n",
    "def is_prime(num):\n",
    "    if num <= 1:\n",
    "        return False\n",
    "    elif num <= 3:\n",
    "        return True\n",
    "    elif num%2 == 0 or num%3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i*i <= num:\n",
    "        if num%i == 0 or num%(i+2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    with Pool(1) as p:\n",
    "        print(p.map(sum_prime, [1000000, 2000000, 3000000]))\n",
    "    print(\"Time taken = {0:.5f}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Memory – mpi4Py\n",
    "\n",
    "Each processor (CPU or core) accesses its own memory and processes a job. If a processor needs to access data resident in the memory owned by another processor, these two processors need to exchange “messages”. Python supports MPI (Message Passing Interface) through `mpi4py` module. `mpi4py` provides open source python bindings to most of the functionality of the MPI-2 standard of the message passing interface MPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world from process  0\n"
     ]
    }
   ],
   "source": [
    "#helloWorld_MPI.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(\"hello world from process \", rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MPI, the processes involved in the execution of a parallel program are identified by a sequence of non-negative integers called ranks. \n",
    "\n",
    "If we have a number p of processes that runs a program, the processes will then have a rank that goes from 0 to `p-1`. The function MPI that comes to us to solve this problem has the following function calls:\n",
    "\n",
    "```python\n",
    "rank = comm.Get_rank()\n",
    "```\n",
    "\n",
    "This function returns the rank of the process that called it. The comm argument is called a communicator, as it defines its own set of all processes that can communicate together:\n",
    "\n",
    "```python\n",
    "comm = MPI.COMM_WORLD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world from process  0\r\n",
      "hello world from process  4\r\n",
      "hello world from process  1\r\n",
      "hello world from process  2\r\n",
      "hello world from process  3\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python helloWorld_MPI.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As multiple processes can apply at the same time by writing on the screen and the operating system arbitrarily chooses the order.\n",
    "\n",
    "Every process involved in the execution of MPI runs the same compiled binary, so each process receives the same instructions to be executed.\n",
    "\n",
    "All the communication functions (point-to-pointor collective) refer to a group of processes. `MPI_COMM_WORLD` assigns a rank `0` to `n-1` for each process that belong to a communicator of size `n`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-to-point communication\n",
    "\n",
    "One of the most important features among those provided by MPI is the point-to-point communication, which is a mechanism that enables data transmission between two processes: **a process receiver**, and a **process sender**.\n",
    "\n",
    "The Python module mpi4py enables point-to-point communication via two functions:\n",
    "* `Comm.Send(data, process_destination)`: This sends data to the destination process identified by its rank in the communicator group\n",
    "* `Comm.Recv(process_source)`: This receives data from the source process, which is also identified by its rank in the communicator group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pointToPointCommunication.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 0:\n",
    "    data = 10000000\n",
    "    destination_process = 4\n",
    "    comm.send(data, dest=destination_process)\n",
    "    print(\"sending data %s to process %d\" % (data, destination_process))\n",
    "\n",
    "if rank == 1:\n",
    "    destination_process = 8\n",
    "    data = \"hello\"\n",
    "    comm.send(data, dest=destination_process)\n",
    "    print(\"sending data %s to process %d\" % (data, destination_process))\n",
    "\n",
    "if rank == 4:\n",
    "    data = comm.recv(source=0)\n",
    "    print(\"data received is = %s\" % data)\n",
    "\n",
    "if rank == 8:\n",
    "    data1 = comm.recv(source=1)\n",
    "    print(\"data1 received is = %s\" % data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n",
      "sending data 10000000 to process 4\n",
      "my rank is :  3\n",
      "my rank is :  4\n",
      "data received is = 10000000\n",
      "my rank is :  8\n",
      "my rank is :  5\n",
      "my rank is :  6\n",
      "my rank is :  1\n",
      "sending data hello to process 8\n",
      "data1 received is = hello\n",
      "my rank is :  2\n",
      "my rank is :  7\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python pointToPointCommunication.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comm.send()` and `comm.recv()` functions are blocking functions: they block the caller until the buffered data involved can safely be used. Also in MPI, there are two management methods of sending and receiving messages:\n",
    "* The buffered mode \n",
    "* The synchronous mode\n",
    "\n",
    "In the buffered mode, the flow control returns to the program as soon as the data to be sent has been copied to a buffer. This does not mean that the message is sent or received. In the synchronous mode, however, the function only gets terminated when the corresponding receive function begins receiving the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadlock problem\n",
    "\n",
    "A common problem we face is that of the deadlock, where two (or more) processes block each other and wait for the other to perform a certain action that serves to another, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "    \n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  5\n",
      "my rank is :  7\n",
      "my rank is :  0\n",
      "my rank is :  1\n",
      "my rank is :  2\n",
      "my rank is :  4\n",
      "my rank is :  6\n",
      "my rank is :  3\n",
      "my rank is :  8\n",
      "^C\n",
      "[mpiexec@Qiweis-MBP.lan] Sending Ctrl-C to processes as requested\n",
      "[mpiexec@Qiweis-MBP.lan] Press Ctrl-C again to force abort\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both prepare to receive a message from the other and get stuck there. This happens because the function MPI `comm.recv()` as well as the `comm.send()` MPI blocks them. It means that the calling process waits for their completion. As for the `comm.send()` MPI, the completion occurs when the data has been sent and may be overwritten without modifying the message. The completion of the `comm.recv()` MPI, instead, is when the data has been received and can be used.\n",
    "\n",
    "The solution that allows us to avoid deadlocks is used to swap the sending and receiving functions so as to make them asymmetrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems2.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "    data_received = comm.recv(source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  1\r\n",
      "my rank is :  2\r\n",
      "my rank is :  3\r\n",
      "my rank is :  4\r\n",
      "my rank is :  7\r\n",
      "my rank is :  5\r\n",
      "sending data a to process 5\r\n",
      "data received is = b\r\n",
      "sending data b to process 1\r\n",
      "data received is = a\r\n",
      "my rank is :  6\r\n",
      "my rank is :  0\r\n",
      "my rank is :  8\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to the deadlock is not the only solution. MPI has a particular function `sendrecv()` that unifies the single call that sends a message to a given process and receives another message that comes from another process.\n",
    "\n",
    "In this case, the function blocks, but compared to the two already seen previously it offers the advantage of leaving the communication subsystem responsible for checking the dependencies between sending and receiving, thus avoiding the deadlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems3.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.sendrecv(data_send, dest=destination_process,\n",
    "                                  source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    data_received = comm.sendrecv(data_send, dest=destination_process,\n",
    "                                  source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  3\r\n",
      "my rank is :  5\r\n",
      "my rank is :  0\r\n",
      "my rank is :  8\r\n",
      "my rank is :  7\r\n",
      "my rank is :  1\r\n",
      "my rank is :  2\r\n",
      "sending data b to process 1\r\n",
      "data received is = a\r\n",
      "my rank is :  6\r\n",
      "sending data a to process 5\r\n",
      "data received is = b\r\n",
      "my rank is :  4\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Collective communication using broadcast\n",
    "\n",
    "During the development of a parallel code, we often find ourselves in the situation where we have to share between multiple processes the value of a certain variable at runtime or certain operations on variables that each process provides (presumably with different values).\n",
    "\n",
    "To resolve this type of situations, the communication trees are used (for example the process 0 sends data to the processes 1 and 2, which respectively will take care of sending them to the processes 3, 4, 5, and 6, and so on).\n",
    "\n",
    "Instead, MPI libraries provide functions ideal for the exchange of information or the use of multiple processes that are clearly optimized for the machine in which they are performed.\n",
    "\n",
    "A communication method that involves all the processes belonging to a communicator is called a collective communication. Consequently, a collective communication generally involves more than two processes. However, instead of this, we will call the collective communication broadcast, wherein a single process sends the same data to any other process. \n",
    "\n",
    "The mpi4py functionalities in the broadcast are offered by the following method:\n",
    "\n",
    "```python\n",
    "buf = comm.bcast(data_to_share, rank_of_root_process)\n",
    "```\n",
    "We have a root process of `rank` equal to zero that shares its own data, `variable_to_share`, with the other processes defined in the communicator group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 0 variable shared = 100\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    variable_to_share = 100\n",
    "else:\n",
    "    variable_to_share = None\n",
    "\n",
    "variable_to_share = comm.bcast(variable_to_share, root=0)\n",
    "print(\"process = %d variable shared = %d\" %(rank, variable_to_share))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process root of rank zero instantiates a variable, `variabile_to_share`, equal to 100. This variable will be shared with the other processes of the communication group. \n",
    "\n",
    "In our case, we have a communication group of ten processes, variable_to_share is shared between the others processes in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 2 variable shared = 100\r\n",
      "process = 3 variable shared = 100\r\n",
      "process = 4 variable shared = 100\r\n",
      "process = 5 variable shared = 100\r\n",
      "process = 6 variable shared = 100\r\n",
      "process = 7 variable shared = 100\r\n",
      "process = 0 variable shared = 100\r\n",
      "process = 1 variable shared = 100\r\n",
      "process = 8 variable shared = 100\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python broadcast.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using scatter\n",
    "\n",
    "The scatter functionality is very similar to a scatter broadcast but has one major difference, while `comm.bcast` sends the same data to all listening processes, `comm.scatter` can send the chunks of data in an array to different processes. \n",
    "\n",
    "The `comm.scatter` function takes the elements of the array and distributes them to the processes according to their rank, for which the first element will be sent to the process zero, the second element to the process 1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    array_to_share = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "else:\n",
    "    array_to_share = None\n",
    "\n",
    "recvbuf = comm.scatter(array_to_share, root=0)\n",
    "print(\"process = %d recvbuf = %d \" % (rank, array_to_share))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of rank zero distributes the `array_to_share` data structure to other processes. \n",
    "\n",
    "The `recvbuf` parameter indicates the value of the ith variable that will be sent to the ith process through the `comm.scatter` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 2, recvbuf = 3 \r\n",
      "process = 3, recvbuf = 4 \r\n",
      "process = 4, recvbuf = 5 \r\n",
      "process = 5, recvbuf = 6 \r\n",
      "process = 0, recvbuf = 1 \r\n",
      "process = 8, recvbuf = 9 \r\n",
      "process = 6, recvbuf = 7 \r\n",
      "process = 7, recvbuf = 8 \r\n",
      "process = 1, recvbuf = 2 \r\n",
      "process = 9, recvbuf = 10 \r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 10 python scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the restrictions to `comm.scatter` is that you can scatter as many elements as the processors you specify in the execution statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"scatter.py\", line 11, in <module>\n",
      "    recvbuf = comm.scatter(array_to_share, root=0)\n",
      "  File \"mpi4py/MPI/Comm.pyx\", line 1267, in mpi4py.MPI.Comm.scatter\n",
      "  File \"mpi4py/MPI/msgpickle.pxi\", line 731, in mpi4py.MPI.PyMPI_scatter\n",
      "  File \"mpi4py/MPI/msgpickle.pxi\", line 120, in mpi4py.MPI.Pickle.dumpv\n",
      "ValueError: expecting 5 items, got 10\n",
      "^C\n",
      "[mpiexec@Qiweis-MacBook-Pro.local] Sending Ctrl-C to processes as requested\n",
      "[mpiexec@Qiweis-MacBook-Pro.local] Press Ctrl-C again to force abort\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using gather\n",
    "\n",
    "The `gather` function performs the inverse of the scatter functionality. In this case, all processes send data to a root process that collects the data received.\n",
    "\n",
    "```python\n",
    "recvbuf = comm.gather(sendbuf, rank_of_root_process)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "data = (rank + 1) ** 2\n",
    "\n",
    "data = comm.gather(data, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"rank = %s ...receiving data to other process\" % rank)\n",
    "\n",
    "    for i in range(1, size):\n",
    "        data[i] = (i + 1) ** 2\n",
    "        value = data[i]\n",
    "        print(\" process %s receiving %s from process %s\" % (rank, value, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank = 0 ...receiving data to other process\r\n",
      " process 0 receiving 4 from process 1\r\n",
      " process 0 receiving 9 from process 2\r\n",
      " process 0 receiving 16 from process 3\r\n",
      " process 0 receiving 25 from process 4\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python gather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using Alltoall\n",
    "\n",
    "The `Alltoall` collective communication combines the `scatter` and `gather` functionality. In `mpi4py`, there are three types of `Alltoall` collective communication:\n",
    "* `comm.Alltoall(sendbuf, recvbuf)`: The all-to-all scatter/gather sends data from all-to-all processes in a group\n",
    "* `comm.Alltoallv(sendbuf, recvbuf)`: The all-to-all scatter/gather vector sends data from all-to-all processes in a group, providing different amount of data and displacements\n",
    "* `comm.Alltoallw(sendbuf, recvbuf)`: Generalized all-to-all communication allows different counts, displacements, and datatypes for each partner\n",
    "\n",
    "We consider a communicator group of processes, where each process sends and receives an array of numerical data from the other processes defined in the group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alltoall.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "a_size = 1\n",
    "senddata = (rank + 1) * np.arange(size, dtype=int)\n",
    "recvdata = np.empty(size * a_size, dtype=int)\n",
    "comm.Alltoall(senddata, recvdata)\n",
    "\n",
    "print(\" process %s sending %s receiving %s\" % (rank, senddata, recvdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " process 4 sending [ 0  5 10 15 20] receiving [ 4  8 12 16 20]\r\n",
      " process 3 sending [ 0  4  8 12 16] receiving [ 3  6  9 12 15]\r\n",
      " process 0 sending [0 1 2 3 4] receiving [0 0 0 0 0]\r\n",
      " process 1 sending [0 2 4 6 8] receiving [1 2 3 4 5]\r\n",
      " process 2 sending [ 0  3  6  9 12] receiving [ 2  4  6  8 10]\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python alltoall.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comm.Alltoall` method takes the ith object from `sendbuf` of the task j and copies it into the jth object of the `recvbuf` argument of the task i.\n",
    "\n",
    "![alt text](image/alltoall.png \"Alltoall collective communication\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reduction operation\n",
    "Similar to `comm.gather`, `comm.reduce` takes an array of input elements in each process and returns an array of output elements to the root process. The output elements contain the reduced result.\n",
    "```python\n",
    "comm.Reduce(sendbuf, recvbuf, rank_of_root_process, op = type_of_ reduction_operation)\n",
    "```\n",
    "`op` parameter contains a set of reduction operations, such as:\n",
    "* MPI.MAX: returns the maximum element\n",
    "* MPI.MIN: reutns the minimum element\n",
    "* MPI.SUM: sum up the elements\n",
    "* MPI.PROD: multiplies all elements\n",
    "* MPI.LAND: performs a logical operation across elements\n",
    "* MPI.MAXLOC: returns the maximum value and the rank of the process that owns it\n",
    "* MPI.MINLOC: returns the minimum value and the rank of the process that owns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduction.py\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.size\n",
    "rank = comm.rank\n",
    "\n",
    "array_size = 3\n",
    "recvdata = np.zeros(array_size, dtype=np.int)\n",
    "senddata = (rank + 1) * np.arange(array_size, dtype=np.int)\n",
    "\n",
    "print(\" process %s sending %s \" % (rank, senddata))\n",
    "comm.Reduce(senddata, recvdata, root=0, op=MPI.SUM)\n",
    "print(\"on task %d after Reduce: data = %s\" % (rank, recvdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " process 0 sending [0 1 2] \r\n",
      " process 1 sending [0 2 4] \r\n",
      " process 2 sending [0 3 6] \r\n",
      "on task 2 after Reduce: data = [0 0 0]\r\n",
      "on task 1 after Reduce: data = [0 0 0]\r\n",
      "on task 0 after Reduce: data = [ 0  6 12]\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 3 python reduction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the op=MPI.SUM option, the reduction operation sums the ith elements of each task and then puts the result in the ith element of the array in the root process P0.\n",
    "\n",
    "![alt text](image/reduction.png \"The reduction collective communication\")\n",
    "\n",
    "What will be the output if we apply option MPI.PROD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
