{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parallel Programming\n",
    "\n",
    "Once all the options in “serial (or sequential) processing” paradigm have been exhausted, and if we\n",
    "still need further speed-up, “parallel processing” is the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared memory - multiprocessing\n",
    "\n",
    "Processors share the access to the same memory. OpenMP is a typical example. OpenMP enables\n",
    "concurrently running multiple threads, with the runtime environment allocating threads to different\n",
    "processors. \n",
    "\n",
    "Python has Global Interpreter Lock (GIL), which prevents multiple native threads from\n",
    "executing Python bytecodes at once, and as a result, there is no OpenMP package for Python.\n",
    "\n",
    "Python's standard \"multiprocessing\" module implements the shared memory programing paradigm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to spawn a process\n",
    "\n",
    "The term \"spawn\" means the creation of a process by a parent process. The parent process can continue its execution asynchronously or wait until the child process ends its execution. \n",
    "\n",
    "The `multiprocessing` library allows the spawning of a process through the following steps:\n",
    "\n",
    "1. Build the object process\n",
    "2. Call its `start()` method. This method starts the process's activity\n",
    "3. Call its `join()` method. It waits until the process has completed its works and exited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called function in process: 0\n",
      "called function in process: 1\n",
      "called function in process: 2\n",
      "called function in process: 3\n",
      "called function in process: 4\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def call(i):\n",
    "    print('called function in process: %s' %i)\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Process_jobs = []\n",
    "    for i in range(5):\n",
    "        p = Process(target=call, args=(i,))\n",
    "        Process_jobs.append(p)\n",
    "        p.start()\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the `Process` object within the main section `if __name__ == '__main__'` is important, because the child process created imports the script file where the target function is contained. Then, by instantiating the process object within this block, we prevent an infinite recursive call of such instantiations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "Process::  Process1\n",
      "Was assigned PID::  13606\n",
      "Process::  Process2\n",
      "Was assigned PID::  13607\n",
      "Process::  Process3\n",
      "Was assigned PID::  13608\n",
      "Process::  Process4\n",
      "Was assigned PID::  13609\n",
      "Process::  Process5\n",
      "Was assigned PID::  13610\n",
      "Process::  Process6\n",
      "Was assigned PID::  13611\n",
      "Process::  Process7\n",
      "Was assigned PID::  13612\n",
      "Process::  Process8\n",
      "Was assigned PID::  13613\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Process\n",
    "\n",
    "# dummy function\n",
    "def f(id):\n",
    "    #This is a dummy function taking a parameter\n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # get the number of CPUs\n",
    "    np = mp.cpu_count()\n",
    "    print('You have %d CPUs' %(np))\n",
    "\n",
    "    # Create the processes\n",
    "    p_list=[]\n",
    "    for i in range(1,np+1):\n",
    "        p = Process(target=f, name='Process'+str(i), args=(i,))\n",
    "        p_list.append(p)\n",
    "        print('Process:: ', p.name)\n",
    "        p.start()\n",
    "        print('Was assigned PID:: ', p.pid)\n",
    "\n",
    "    # Wait for all the processes to finish\n",
    "    for p in p_list:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to name a process\n",
    "\n",
    "It is very useful to associate a name to the processes as debugging an anpplication requires the processes to be well marked and identifiable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting call_process \n",
      "\n",
      "Starting Process-19 \n",
      "\n",
      "Exiting call_process \n",
      "\n",
      "Exiting Process-19 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def call():\n",
    "    name = mp.current_process().name\n",
    "    print(\"Starting %s \\n\" %name)\n",
    "    time.sleep(3)\n",
    "    print(\"Exiting %s \\n\" %name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_with_name = mp.Process(name='call_process', target=call)\n",
    "    process_with_default_name = mp.Process(target=call)\n",
    "    \n",
    "    process_with_name.start()\n",
    "    process_with_default_name.start()\n",
    "    process_with_name.join()\n",
    "    process_with_default_name.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use a process in a subclass\n",
    "\n",
    "* Define a new subclass of the `Process` class\n",
    "* Override the `_init__(self[, args])` method to add additional arguments\n",
    "* Override the `run(self[, args])` method to implement what Process should when it is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called run method in process: MyProcess-25\n",
      "called run method in process: MyProcess-26\n",
      "called run method in process: MyProcess-27\n",
      "called run method in process: MyProcess-28\n",
      "called run method in process: MyProcess-29\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "class MyProcess(mp.Process):\n",
    "    def run(self):\n",
    "        print('called run method in process: %s' %self.name)\n",
    "        return\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = MyProcess()\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to exchange objects between processes\n",
    "\n",
    "The `multiprocessing` library has two communication channels with which it manages the exchange of objects: queues and pipes.\n",
    "\n",
    "<img src=\"image/communication.png\" alt=\"Communication channels\" style=\"width: 500px;, height:400px\"/>\n",
    "\n",
    "#### Using queue to exchange objects\n",
    "The queue returns a process shared queue to allow any serializalbe object to be exchanged through it.\n",
    "\n",
    "Below shows you how to use a queue for a producer-consumer problem. The `producer` class creates the item and queues and then, the `consumer` class provides the facility to remove the inserted item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Producer : item 79 appended to queue producer-32\n",
      "Process Producer : item 233 appended to queue producer-32\n",
      "Process Producer : item 167 appended to queue producer-32\n",
      "Processor Consumer: item 79 popped from by consumer-33 \n",
      "\n",
      "Process Producer : item 217 appended to queue producer-32\n",
      "Process Producer : item 16 appended to queue producer-32\n",
      "Processor Consumer: item 233 popped from by consumer-33 \n",
      "\n",
      "Process Producer : item 87 appended to queue producer-32\n",
      "Process Producer : item 114 appended to queue producer-32\n",
      "Process Producer : item 75 appended to queue producer-32\n",
      "Processor Consumer: item 167 popped from by consumer-33 \n",
      "\n",
      "Process Producer : item 129 appended to queue producer-32\n",
      "Process Producer : item 188 appended to queue producer-32\n",
      "Processor Consumer: item 217 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 16 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 87 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 114 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 75 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 129 popped from by consumer-33 \n",
      "\n",
      "Processor Consumer: item 188 popped from by consumer-33 \n",
      "\n",
      "the queue is empty\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import time\n",
    "\n",
    "class producer(mp.Process):\n",
    "    def __init__(self, queue):\n",
    "        mp.Process.__init__(self)\n",
    "        self.queue = queue\n",
    "        \n",
    "    def run(self):\n",
    "        for i in range(10):\n",
    "            item = random.randint(0, 256)\n",
    "            self.queue.put(item)\n",
    "            print(\"Process Producer : item %d appended to queue %s\"\\\n",
    "                  % (item, self.name))\n",
    "            time.sleep(1)\n",
    "            #print(\"The size of queue is %s\" % self.queue.qsize()) # Unix system throws error\n",
    "            \n",
    "class consumer(mp.Process):\n",
    "    def __init__(self, queue):\n",
    "        mp.Process.__init__(self)\n",
    "        self.queue = queue\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            if(self.queue.empty()):\n",
    "                print(\"the queue is empty\")\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(2)\n",
    "                item = self.queue.get()\n",
    "                print('Processor Consumer: item %d popped from by %s \\n'\\\n",
    "                     % (item, self.name))\n",
    "                time.sleep(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queue = mp.Queue()\n",
    "    process_producer = producer(queue)\n",
    "    process_consumer = consumer(queue)\n",
    "    process_producer.start()\n",
    "    process_consumer.start()\n",
    "    process_producer.join()\n",
    "    process_consumer.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pipes to exchange objects\n",
    "\n",
    "A pipe does the following:\n",
    "* Returns a pair of connection objects connected by a pipe\n",
    "* Every object has send/receive methods to communicate between processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def create_items(pipe):\n",
    "    output_pipe, _ = pipe\n",
    "    for item in range(10):\n",
    "        output_pipe.send(item)\n",
    "    output_pipe.close()\n",
    "    \n",
    "def multiply_items(pipe_1, pipe_2):\n",
    "    close, input_pipe = pipe_1\n",
    "    close.close()\n",
    "    output_pipe, _ = pipe_2\n",
    "    try:\n",
    "        while True:\n",
    "            item = input_pipe.recv()\n",
    "            output_pipe.send(item * item)\n",
    "    except EOFError:\n",
    "        output_pipe.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # First process pipe with numbers from 0 to 9\n",
    "    pipe_1 = mp.Pipe(True)\n",
    "    process_pipe_1 = mp.Process(target=create_items, args=(pipe_1,))\n",
    "    process_pipe_1.start()\n",
    "    \n",
    "    # Second pipe with input and output\n",
    "    pipe_2 = mp.Pipe(True)\n",
    "    process_pipe_2 = mp.Process(target=multiply_items, args=(pipe_1, pipe_2,))\n",
    "    process_pipe_2.start()\n",
    "    \n",
    "    pipe_1[0].close()\n",
    "    pipe_2[0].close()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            print(pipe_2[1].recv())\n",
    "            \n",
    "    except EOFError:\n",
    "        print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to synchronize processes\n",
    "\n",
    "Multiple processes can work together to perform a given task. Usually, they share data. It is important that the access to shared data by various processes does not produce inconsistent data. \n",
    "\n",
    "Processes that coorperate by sharing data must therefore act in an orderly manner in order to access that data. \n",
    "\n",
    "* Lock: This object can be in one of the states: locked and unlocked. A lock object has two methods, `acquire()` and `release()`, to manage the access to a shared resource.\n",
    "* Event: This realizes simple communication between processes, one process signals an event and the other processes wait for it. An `Event` object has two methods, `set()` and `clear()`, to manage its own internal flag.\n",
    "* Condition: This object is used to synchronize parts of a workflow, in sequential or parallel processes. It has two basic methods, `wait()` is used to wait for a condition and `notify_all()` is used to communicate the condition that was applied.\n",
    "* Semaphore: This is used to share a common resource, for example, to support a fixed number of simultaneous connections\n",
    "* RLock: This defines the recursive `lock` object. \n",
    "* Barrier: This divides a program into phases as it requires all of the processes to reach it before any of them proceeds. Code that is executed after a barrier cannot be concurrent with the code executed before the barrier\n",
    "\n",
    "Here we show the use of `barrier()` to synchronize two processes. Say four processes, where process1 and process2 are managed by a barrier statement, while process3 and process4 have no synchronizations directives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process p2 - test_with_barrier ----> 2018-01-25 15:23:43.368023\n",
      "process p1 - test_with_barrier ----> 2018-01-25 15:23:43.368158\n",
      "process p3 - test_without_barrier ----> 2018-01-25 15:23:43.374144\n",
      "process p4 - test_without_barrier ----> 2018-01-25 15:23:43.379637\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from multiprocessing import Barrier, Lock, Process\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "\n",
    "def test_with_barrier(synchronizer, serializer):\n",
    "    name = mp.current_process().name\n",
    "    synchronizer.wait()\n",
    "    now = time()\n",
    "    with serializer:\n",
    "        print(\"process %s ----> %s\" % (name, datetime.fromtimestamp(now)))\n",
    "        \n",
    "def test_without_barrier():\n",
    "    name = mp.current_process().name\n",
    "    now = time()\n",
    "    print(\"process %s ----> %s\" % (name, datetime.fromtimestamp(now)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    synchronizer = Barrier(2) #2 stands for the total number of process\n",
    "    serializer = Lock()\n",
    "    Process(name='p1 - test_with_barrier', target=test_with_barrier, args=(synchronizer, serializer)).start()\n",
    "    Process(name='p2 - test_with_barrier', target=test_with_barrier, args=(synchronizer, serializer)).start()\n",
    "    Process(name='p3 - test_without_barrier', target=test_without_barrier).start()\n",
    "    Process(name='p4 - test_without_barrier', target=test_without_barrier).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_with_barrier` function executes the barrier's `wait()` method. When the two processes have called the `wait()` method, they are released simultaneously. \n",
    "\n",
    "We can see that process1 and process2 print out the much closer timestamps than process3 and process4.\n",
    "<img src=\"image/barrier.png\" alt=\"Process managment with a barrier\" style=\"width: 500px;, height:400px\"/>\n",
    "\n",
    "### How to manage a state between processes\n",
    "Python multiprocessing provides a manager to coordinate shared information between all its users. A manager object controls a server process that holds Python objects and allows other processes to manipulate them. \n",
    "\n",
    "A manager has the following properties:\n",
    "* It controls the server process that manages a shared object\n",
    "* It makes sure the shared object gets updated in all processes when anyone modifies it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key = 0, value = 0\n",
      "key = 1, value = 1\n",
      "key = 2, value = 4\n",
      "key = 3, value = 9\n",
      "key = 4, value = 16\n",
      "key = 5, value = 25\n",
      "key = 6, value = 36\n",
      "key = 7, value = 49\n",
      "key = 8, value = 64\n",
      "key = 9, value = 81\n",
      "Results: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def worker(dictionary, key, item):\n",
    "    dictionary[key] = item\n",
    "    print(\"key = %d, value = %d\" % (key, item))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mgr = mp.Manager()\n",
    "    dictionary = mgr.dict()\n",
    "    jobs = [mp.Process(target=worker, args=(dictionary, i, i**2)) for i in range(10)]\n",
    "    \n",
    "    for j in jobs:\n",
    "        j.start()\n",
    "    for j in jobs:\n",
    "        j.join()\n",
    "    \n",
    "    print('Results:', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program creates a manager list, shares it between n number of `taskWorkers`, and every worker updates an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use a process pool\n",
    "The multiprocessing library provides the `Pool` class for simple parallel processing tasks. \n",
    "\n",
    "The `Pool` class has the following methods:\n",
    "* `apply()`: It blocks until the result is ready\n",
    "* `apply_async()`: This is a variant of the `apply()` method, which returns a result object. It is an asynchronous operation that will not lock the main thread until all the child classes are executed\n",
    "* `map()`: It blocks until the result is ready, this method chops the iterable data in a number of chunks that submits to the process pool as separate tasks. \n",
    "* `map_async()`: If a callback is specified, then it should be callable, which accepts a single argument. When the result becomes ready, a callback is applied to it (unless the call failed). A callback should be completed immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def square(data):\n",
    "    result = data*data\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = list(range(100))\n",
    "    pool = mp.Pool(processes=4)\n",
    "    pool_outputs = pool.map(square, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('Pool:', pool_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial vs. parallel programming\n",
    "\n",
    "Let's revisit the case of computing Pi using numerical integration. Now we want to calculate the Pi for multiple times with different number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415927369231227, 3.14159267442312, 3.141592662849059, 3.141592658798146, 3.1415926569231227, 3.1415926559046072, 3.1415926552904714, 3.1415926548918773]\n",
      "Time taken 0.007169961929321289 second\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(1000, 9000, 1000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415927369231227, 3.14159267442312, 3.141592662849059, 3.141592658798146, 3.1415926569231227, 3.1415926559046072, 3.1415926552904714, 3.1415926548918773]\n",
      "Time taken 0.1488640308380127 second\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000, 9000, 1000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel model actually takes much longer time!! How could this happen?\n",
    "\n",
    "Let's assume we want more CPU intensive task, by increasing the number of steps by three order of maginitude when estimating Pi value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 6.052393913269043 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(1000000, 9000000, 1000000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 2.003614902496338 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000000, 9000000, 1000000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the paralle model performs faster. It is because tasks are performed by multiple cores.\n",
    "\n",
    "What if we keep increasing the computation intesntity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1415926535904264, 3.141592653590478, 3.141592653589358, 3.141592653589552, 3.141592653589814, 3.1415926535893726, 3.141592653589768, 3.1415926535889573]\n",
      "Time taken 620.9813508987427 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "    \n",
    "    return pi\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    pi = []\n",
    "    for steps in range(100000000, 900000000, 100000000):\n",
    "        pi.append(Pi(steps))\n",
    "\n",
    "    print(pi)\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "[3.1415926535897643, 3.141592653589994, 3.1415926535896097, 3.141592653589683, 3.141592653589587, 3.1415926535895613, 3.1415926535900187, 3.1415926535900724]\n",
      "Time taken 1.8940212726593018 second\n"
     ]
    }
   ],
   "source": [
    "def Pi(num_steps):\n",
    "\n",
    "    step = 1.0/num_steps\n",
    "    sum = 0\n",
    "    for i in range(num_steps):\n",
    "        x= (i+0.5)*step\n",
    "        sum = sum + 4.0/(1.0+x*x)\n",
    "        pi = step * sum\n",
    "        \n",
    "    return pi\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have {0:1d} CPUs'.format(np))\n",
    "    start = time.time()\n",
    "    with Pool(np) as p:\n",
    "        print(p.map(Pi, list(range(1000000, 9000000, 1000000))))\n",
    "    print(\"Time taken %s second\" %(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the benchmark to understand how multi-core parallel computing can be beneificial to computing intensive tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 8 CPUs\n",
      "Esitmated value of Pi::  3.1413072\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#caculate the number of points in the unit circle out of n points\n",
    "def monte_carlo_pi_part(n):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(int(n)):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        \n",
    "        # if it is within the unit circle\n",
    "        if x*x + y*y <= 1:\n",
    "            count=count+1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    np = multiprocessing.cpu_count()\n",
    "    print('You have %d CPUs' % np)\n",
    "\n",
    "    # Nummber of points to use for the Pi estimation\n",
    "    n = 10000000\n",
    "    \n",
    "    # iterable with a list of points to generate in each worker\n",
    "    # each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "    part_count = [n/np] * np\n",
    "\n",
    "    #Create the worker pool\n",
    "    # http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool\n",
    "    pool = Pool(processes=np)   \n",
    "\n",
    "    # parallel map\n",
    "    count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "    print(\"Esitmated value of Pi:: \", sum(count)/(n*1.0)*4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use the multiprocessing to calculate the sum of prime numbers less than n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37550402023, 142913828922, 312471072265]\n",
      "Time taken = 23.71322\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def sum_prime(num):\n",
    "    \n",
    "    sum_of_primes = 0\n",
    "\n",
    "    ix = 2\n",
    "\n",
    "    while ix <= num:\n",
    "        if is_prime(ix):\n",
    "            sum_of_primes += ix\n",
    "        ix += 1\n",
    "\n",
    "    return sum_of_primes\n",
    "\n",
    "def is_prime(num):\n",
    "    if num <= 1:\n",
    "        return False\n",
    "    elif num <= 3:\n",
    "        return True\n",
    "    elif num%2 == 0 or num%3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i*i <= num:\n",
    "        if num%i == 0 or num%(i+2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Memory – mpi4Py\n",
    "\n",
    "Each processor (CPU or core) accesses its own memory and processes a job. If a processor needs to access data resident in the memory owned by another processor, these two processors need to exchange “messages”. Python supports MPI (Message Passing Interface) through `mpi4py` module. `mpi4py` provides open source python bindings to most of the functionality of the MPI-2 standard of the message passing interface MPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world from process  0\n"
     ]
    }
   ],
   "source": [
    "#helloWorld_MPI.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "print(\"hello world from process \", rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In MPI, the processes involved in the execution of a parallel program are identified by a sequence of non-negative integers called ranks. \n",
    "\n",
    "If we have a number p of processes that runs a program, the processes will then have a rank that goes from 0 to `p-1`. The function MPI that comes to us to solve this problem has the following function calls:\n",
    "\n",
    "```python\n",
    "rank = comm.Get_rank()\n",
    "```\n",
    "\n",
    "This function returns the rank of the process that called it. The comm argument is called a communicator, as it defines its own set of all processes that can communicate together:\n",
    "\n",
    "```python\n",
    "comm = MPI.COMM_WORLD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world from process  0\r\n",
      "hello world from process  1\r\n",
      "hello world from process  2\r\n",
      "hello world from process  3\r\n",
      "hello world from process  4\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python helloWorld_MPI.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As multiple processes can apply at the same time by writing on the screen and the operating system arbitrarily chooses the order.\n",
    "\n",
    "Every process involved in the execution of MPI runs the same compiled binary, so each process receives the same instructions to be executed.\n",
    "\n",
    "All the communication functions (point-to-pointor collective) refer to a group of processes. `MPI_COMM_WORLD` assigns a rank `0` to `n-1` for each process that belong to a communicator of size `n`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-to-point communication\n",
    "\n",
    "One of the most important features among those provided by MPI is the point-to-point communication, which is a mechanism that enables data transmission between two processes: **a process receiver**, and a **process sender**.\n",
    "\n",
    "The Python module mpi4py enables point-to-point communication via two functions:\n",
    "* `Comm.Send(data, process_destination)`: This sends data to the destination process identified by its rank in the communicator group\n",
    "* `Comm.Recv(process_source)`: This receives data from the source process, which is also identified by its rank in the communicator group\n",
    "\n",
    "<img src=\"image/send_receive.png\" alt=\"Send/receive transmission protocol\" style=\"width: 500px;, height:400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pointToPointCommunication.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 0:\n",
    "    data = 10000000\n",
    "    destination_process = 4\n",
    "    comm.send(data, dest=destination_process)\n",
    "    print(\"sending data %s to process %d\" % (data, destination_process))\n",
    "\n",
    "if rank == 1:\n",
    "    destination_process = 8\n",
    "    data = \"hello\"\n",
    "    comm.send(data, dest=destination_process)\n",
    "    print(\"sending data %s to process %d\" % (data, destination_process))\n",
    "\n",
    "if rank == 4:\n",
    "    data = comm.recv(source=0)\n",
    "    print(\"data received is = %s\" % data)\n",
    "\n",
    "if rank == 8:\n",
    "    data1 = comm.recv(source=1)\n",
    "    print(\"data received is = %s\" % data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  5\r\n",
      "my rank is :  2\r\n",
      "my rank is :  8\r\n",
      "my rank is :  6\r\n",
      "my rank is :  0\r\n",
      "sending data 10000000 to process 4\r\n",
      "my rank is :  1\r\n",
      "sending data hello to process 8\r\n",
      "data received is = hello\r\n",
      "my rank is :  7\r\n",
      "my rank is :  4\r\n",
      "my rank is :  3\r\n",
      "data received is = 10000000\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python pointToPointCommunication.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comm.send()` and `comm.recv()` functions are blocking functions: they block the caller until the buffered data involved can safely be used. Also in MPI, there are two management methods of sending and receiving messages:\n",
    "* The buffered mode \n",
    "* The synchronous mode\n",
    "\n",
    "In the buffered mode, the flow control returns to the program as soon as the data to be sent has been copied to a buffer. This does not mean that the message is sent or received. In the synchronous mode, however, the function only gets terminated when the corresponding receive function begins receiving the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadlock problem\n",
    "\n",
    "A common problem we face is that of the deadlock, where two (or more) processes block each other and wait for the other to perform a certain action that serves to another, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "    \n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  4\n",
      "my rank is :  0\n",
      "my rank is :  3\n",
      "my rank is :  1\n",
      "my rank is :  5\n",
      "my rank is :  8\n",
      "my rank is :  6\n",
      "my rank is :  7\n",
      "my rank is :  2\n",
      "^C\n",
      "[mpiexec@Qiweis-MBP.lan] Sending Ctrl-C to processes as requested\n",
      "[mpiexec@Qiweis-MBP.lan] Press Ctrl-C again to force abort\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2899:\n",
      "Process ForkPoolWorker-2900:\n",
      "Process ForkPoolWorker-2896:\n",
      "Process ForkPoolWorker-2895:\n",
      "Process ForkPoolWorker-2897:\n",
      "Process ForkPoolWorker-2894:\n",
      "Process ForkPoolWorker-2898:\n",
      "Process ForkPoolWorker-2893:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both prepare to receive a message from the other and get stuck there. This happens because the function MPI `comm.recv()` as well as the `comm.send()` MPI blocks them. It means that the calling process waits for their completion. As for the `comm.send()` MPI, the completion occurs when the data has been sent and may be overwritten without modifying the message. The completion of the `comm.recv()` MPI, instead, is when the data has been received and can be used.\n",
    "\n",
    "The solution that allows us to avoid deadlocks is used to swap the sending and receiving functions so as to make them asymmetrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems2.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.recv(source=source_process)\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    comm.send(data_send, dest=destination_process)\n",
    "    data_received = comm.recv(source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  5\r\n",
      "my rank is :  7\r\n",
      "my rank is :  8\r\n",
      "my rank is :  4\r\n",
      "my rank is :  3\r\n",
      "my rank is :  6\r\n",
      "my rank is :  0\r\n",
      "my rank is :  1\r\n",
      "sending data a to process 5\r\n",
      "data received is = b\r\n",
      "sending data b to process 1\r\n",
      "data received is = a\r\n",
      "my rank is :  2\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution to the deadlock is not the only solution. MPI has a particular function `sendrecv()` that unifies the single call that sends a message to a given process and receives another message that comes from another process.\n",
    "\n",
    "In this case, the function blocks, but compared to the two already seen previously it offers the advantage of leaving the communication subsystem responsible for checking the dependencies between sending and receiving, thus avoiding the deadlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  0\n"
     ]
    }
   ],
   "source": [
    "# deadLockProblems3.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "print(\"my rank is : \", rank)\n",
    "\n",
    "if rank == 1:\n",
    "    data_send = \"a\"\n",
    "    destination_process = 5\n",
    "    source_process = 5\n",
    "\n",
    "    data_received = comm.sendrecv(data_send, dest=destination_process,\n",
    "                                  source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)\n",
    "\n",
    "if rank == 5:\n",
    "    data_send = \"b\"\n",
    "    destination_process = 1\n",
    "    source_process = 1\n",
    "\n",
    "    data_received = comm.sendrecv(data_send, dest=destination_process,\n",
    "                                  source=source_process)\n",
    "\n",
    "    print(\"sending data %s to process %d\" % (data_send, destination_process))\n",
    "    print(\"data received is = %s\" % data_received)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my rank is :  8\n",
      "my rank is :  6\n",
      "my rank is :  4\n",
      "my rank is :  7\n",
      "my rank is :  3\n",
      "my rank is :  0\n",
      "my rank is :  1\n",
      "my rank is :  2\n",
      "my rank is :  5\n",
      "sending data b to process 1\n",
      "data received is = a\n",
      "sending data a to process 5\n",
      "data received is = b\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python deadLockProblems3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Collective communication using broadcast\n",
    "\n",
    "During the development of a parallel code, we often find ourselves in the situation where we have to share between multiple processes the value of a certain variable at runtime or certain operations on variables that each process provides (presumably with different values).\n",
    "\n",
    "To resolve this type of situations, the communication trees are used (for example the process 0 sends data to the processes 1 and 2, which respectively will take care of sending them to the processes 3, 4, 5, and 6, and so on).\n",
    "\n",
    "Instead, MPI libraries provide functions ideal for the exchange of information or the use of multiple processes that are clearly optimized for the machine in which they are performed.\n",
    "\n",
    "A communication method that involves all the processes belonging to a communicator is called a collective communication. Consequently, a collective communication generally involves more than two processes. However, instead of this, we will call the collective communication broadcast, wherein a single process sends the same data to any other process. \n",
    "\n",
    "The mpi4py functionalities in the broadcast are offered by the following method:\n",
    "\n",
    "```python\n",
    "buf = comm.bcast(data_to_share, rank_of_root_process)\n",
    "```\n",
    "\n",
    "<img src=\"image/broadcast.png\" alt=\"Broadcast data from process 0 to process 1,2,3,4\" style=\"width: 500px;, height:400px\"/>\n",
    "\n",
    "We have a root process of `rank` equal to zero that shares its own data, `variable_to_share`, with the other processes defined in the communicator group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 0 variable shared = 100\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    variable_to_share = 100\n",
    "else:\n",
    "    variable_to_share = None\n",
    "\n",
    "variable_to_share = comm.bcast(variable_to_share, root=0)\n",
    "print(\"process = %d variable shared = %d\" %(rank, variable_to_share))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process root of rank zero instantiates a variable, `variabile_to_share`, equal to 100. This variable will be shared with the other processes of the communication group. \n",
    "\n",
    "In our case, we have a communication group of ten processes, variable_to_share is shared between the others processes in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 0 variable shared = 100\n",
      "process = 2 variable shared = 100\n",
      "process = 4 variable shared = 100\n",
      "process = 5 variable shared = 100\n",
      "process = 6 variable shared = 100\n",
      "process = 1 variable shared = 100\n",
      "process = 7 variable shared = 100\n",
      "process = 3 variable shared = 100\n",
      "process = 8 variable shared = 100\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 9 python broadcast.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using scatter\n",
    "\n",
    "The scatter functionality is very similar to broadcast but has one major difference, while `comm.bcast` sends the same data to all listening processes, `comm.scatter` can send the chunks of data in an array to different processes. \n",
    "\n",
    "The `comm.scatter` function takes the elements of the array and distributes them to the processes according to their rank, for which the first element will be sent to the process zero, the second element to the process 1, and so on.\n",
    "\n",
    "<img src=\"image/scattering.png\" alt=\"Scattering data from process 0 to process 1,2,3,4\" style=\"width: 500px;, height:400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scatter.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    array_to_share = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "else:\n",
    "    array_to_share = None\n",
    "\n",
    "recvbuf = comm.scatter(array_to_share, root=0)\n",
    "print(\"process = %d recvbuf = %d \" % (rank, array_to_share))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of rank zero distributes the `array_to_share` data structure to other processes. \n",
    "\n",
    "The `recvbuf` parameter indicates the value of the ith variable that will be sent to the ith process through the `comm.scatter` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process = 4, recvbuf = 5 \r\n",
      "process = 6, recvbuf = 7 \r\n",
      "process = 0, recvbuf = 1 \r\n",
      "process = 5, recvbuf = 6 \r\n",
      "process = 7, recvbuf = 8 \r\n",
      "process = 1, recvbuf = 2 \r\n",
      "process = 8, recvbuf = 9 \r\n",
      "process = 2, recvbuf = 3 \r\n",
      "process = 3, recvbuf = 4 \r\n",
      "process = 9, recvbuf = 10 \r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 10 python scatter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the restrictions to `comm.scatter` is that you can scatter as many elements as the processors you specify in the execution statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"scatter.py\", line 11, in <module>\n",
      "    recvbuf = comm.scatter(array_to_share, root=0)\n",
      "  File \"mpi4py/MPI/Comm.pyx\", line 1267, in mpi4py.MPI.Comm.scatter\n",
      "  File \"mpi4py/MPI/msgpickle.pxi\", line 731, in mpi4py.MPI.PyMPI_scatter\n",
      "  File \"mpi4py/MPI/msgpickle.pxi\", line 120, in mpi4py.MPI.Pickle.dumpv\n",
      "ValueError: expecting 5 items, got 10\n",
      "^C\n",
      "[mpiexec@Qiweis-MBP.lan] Sending Ctrl-C to processes as requested\n",
      "[mpiexec@Qiweis-MBP.lan] Press Ctrl-C again to force abort\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python scatter.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using gather\n",
    "\n",
    "The `gather` function performs the inverse of the scatter functionality. In this case, all processes send data to a root process that collects the data received.\n",
    "\n",
    "```python\n",
    "recvbuf = comm.gather(sendbuf, rank_of_root_process)\n",
    "```\n",
    "\n",
    "<img src=\"image/gathering.png\" alt=\"Gathering data from process 0 to process 1,2,3,4\" style=\"width: 500px;, height:400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gather.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "data = (rank + 1) ** 2\n",
    "\n",
    "data = comm.gather(data, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"rank = %s ...receiving data to other process\" % rank)\n",
    "\n",
    "    for i in range(1, size):\n",
    "        data[i] = (i + 1) ** 2\n",
    "        value = data[i]\n",
    "        print(\" process %s receiving %s from process %s\" % (rank, value, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank = 0 ...receiving data to other process\r\n",
      " process 0 receiving 4 from process 1\r\n",
      " process 0 receiving 9 from process 2\r\n",
      " process 0 receiving 16 from process 3\r\n",
      " process 0 receiving 25 from process 4\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python gather.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective communication using Alltoall\n",
    "\n",
    "The `Alltoall` collective communication combines the `scatter` and `gather` functionality. In `mpi4py`, there are three types of `Alltoall` collective communication:\n",
    "* `comm.Alltoall(sendbuf, recvbuf)`: The all-to-all scatter/gather sends data from all-to-all processes in a group\n",
    "* `comm.Alltoallv(sendbuf, recvbuf)`: The all-to-all scatter/gather vector sends data from all-to-all processes in a group, providing different amount of data and displacements\n",
    "* `comm.Alltoallw(sendbuf, recvbuf)`: Generalized all-to-all communication allows different counts, displacements, and datatypes for each partner\n",
    "\n",
    "We consider a communicator group of processes, where each process sends and receives an array of numerical data from the other processes defined in the group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alltoall.py\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "a_size = 1\n",
    "senddata = (rank + 1) * np.arange(size, dtype=int)\n",
    "recvdata = np.empty(size * a_size, dtype=int)\n",
    "comm.Alltoall(senddata, recvdata)\n",
    "\n",
    "print(\" process %s sending %s receiving %s\" % (rank, senddata, recvdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " process 4 sending [ 0  5 10 15 20] receiving [ 4  8 12 16 20]\r\n",
      " process 3 sending [ 0  4  8 12 16] receiving [ 3  6  9 12 15]\r\n",
      " process 0 sending [0 1 2 3 4] receiving [0 0 0 0 0]\r\n",
      " process 1 sending [0 2 4 6 8] receiving [1 2 3 4 5]\r\n",
      " process 2 sending [ 0  3  6  9 12] receiving [ 2  4  6  8 10]\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python alltoall.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `comm.Alltoall` method takes the ith object from `sendbuf` of the task j and copies it into the jth object of the `recvbuf` argument of the task i.\n",
    "\n",
    "![alt text](image/alltoall.png \"Alltoall collective communication\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reduction operation\n",
    "Similar to `comm.gather`, `comm.reduce` takes an array of input elements in each process and returns an array of output elements to the root process. The output elements contain the reduced result.\n",
    "```python\n",
    "comm.Reduce(sendbuf, recvbuf, rank_of_root_process, op = type_of_ reduction_operation)\n",
    "```\n",
    "`op` parameter contains a set of reduction operations, such as:\n",
    "* MPI.MAX: returns the maximum element\n",
    "* MPI.MIN: reutns the minimum element\n",
    "* MPI.SUM: sum up the elements\n",
    "* MPI.PROD: multiplies all elements\n",
    "* MPI.LAND: performs a logical operation across elements\n",
    "* MPI.MAXLOC: returns the maximum value and the rank of the process that owns it\n",
    "* MPI.MINLOC: returns the minimum value and the rank of the process that owns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduction.py\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.size\n",
    "rank = comm.rank\n",
    "\n",
    "array_size = 3\n",
    "recvdata = np.zeros(array_size, dtype=np.int)\n",
    "senddata = (rank + 1) * np.arange(array_size, dtype=np.int)\n",
    "\n",
    "print(\" process %s sending %s \" % (rank, senddata))\n",
    "comm.Reduce(senddata, recvdata, root=0, op=MPI.SUM)\n",
    "print(\"on task %d after Reduce: data = %s\" % (rank, recvdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " process 0 sending [0 1 2] \r\n",
      " process 1 sending [0 2 4] \r\n",
      " process 2 sending [0 3 6] \r\n",
      "on task 2 after Reduce: data = [0 0 0]\r\n",
      "on task 1 after Reduce: data = [0 0 0]\r\n",
      "on task 0 after Reduce: data = [ 0  6 12]\r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 3 python reduction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the op=MPI.SUM option, the reduction operation sums the ith elements of each task and then puts the result in the ith element of the array in the root process P0.\n",
    "\n",
    "![alt text](image/reduction.png \"The reduction collective communication\")\n",
    "\n",
    "What will be the output if we apply option MPI.PROD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise: implement the MPI version of computing pi using both numerical integration and monte carlo methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi with 100000000000 steps is 3.141593 in 166.923501 secs\r\n"
     ]
    }
   ],
   "source": [
    "!python compute_pi_numba.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esitmated value of Pi:: 3.141593 in 41.804365 seconds \r\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -n 5 python compute_pi_numba_mpi.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
